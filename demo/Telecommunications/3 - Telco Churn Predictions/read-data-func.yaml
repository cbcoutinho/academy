name: Synthesize data
inputs:
- {name: df_churn_ip}
outputs:
- {name: mlpipeline_ui_metadata}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' 'gcsfs'
      'tensorflow==2.2.0' 'seaborn==0.9.0' 'matplotlib==3.1.1' 'mpld3==0.5.1' || PIP_DISABLE_PIP_VERSION_CHECK=1
      python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2'
      'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' 'gcsfs' 'tensorflow==2.2.0'
      'seaborn==0.9.0' 'matplotlib==3.1.1' 'mpld3==0.5.1' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def _make_parent_dirs_and_return_path(file_path: str):
          import os
          os.makedirs(os.path.dirname(file_path), exist_ok=True)
          return file_path

      def synthesize_data(
          df_churn_ip,
          mlpipeline_ui_metadata,
      ):

          from pandas import read_csv
          from tensorflow.python.lib.io import file_io
          import json

          data = read_csv(df_churn_ip)
          sample = data.sample(1000)

          cat_cols=["PaymentMethod","MultipleLines","InternetService","OnlineSecurity","OnlineBackup",
              "DeviceProtection","TechSupport","StreamingTV","StreamingMovies","Contract"]

          schema = [
              {"name": c, "type": "CATEGORY" if c in cat_cols else "NUMBER"}
              for c in data.columns
              ]

          metadata = {
              "outputs": [
                  {
                      "type": "table",
                      "format": "csv",
                      "header": [x["name"] for x in schema],
                      "source": sample.to_csv(index=False),
                      "storage": "inline",
                  }
              ]
          }

          with open('mlpipeline-ui-metadata.json', 'w') as f:
              json.dump(metadata, f)

          with file_io.FileIO(mlpipeline_ui_metadata, "w") as f:
              json.dump(metadata, f)

      import argparse
      _parser = argparse.ArgumentParser(prog='Synthesize data', description='')
      _parser.add_argument("--df-churn-ip", dest="df_churn_ip", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--mlpipeline-ui-metadata", dest="mlpipeline_ui_metadata", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parsed_args = vars(_parser.parse_args())

      _outputs = synthesize_data(**_parsed_args)
    args:
    - --df-churn-ip
    - {inputPath: df_churn_ip}
    - --mlpipeline-ui-metadata
    - {outputPath: mlpipeline_ui_metadata}
