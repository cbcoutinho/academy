name: Categorical analysis
inputs:
- {name: df_churn_ip}
- {name: in_gcp_bucket_project, type: String}
- {name: in_gcp_bucket_output_path, type: String}
- {name: in_gcp_sa_json, type: JsonObject}
outputs:
- {name: mlpipeline_ui_metadata}
- {name: df_churn_op}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' 'gcsfs'
      'tensorflow==2.2.0' 'seaborn==0.9.0' 'matplotlib==3.1.1' 'mpld3==0.5.1' || PIP_DISABLE_PIP_VERSION_CHECK=1
      python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2'
      'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' 'gcsfs' 'tensorflow==2.2.0'
      'seaborn==0.9.0' 'matplotlib==3.1.1' 'mpld3==0.5.1' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def _make_parent_dirs_and_return_path(file_path: str):
          import os
          os.makedirs(os.path.dirname(file_path), exist_ok=True)
          return file_path

      def categorical_analysis(
          df_churn_ip,
          in_gcp_bucket_project,
          in_gcp_bucket_output_path,
          in_gcp_sa_json,
          mlpipeline_ui_metadata,
          df_churn_op,
      ):

          import pandas as pd
          import numpy as np
          import gcsfs
          import seaborn as sns
          import matplotlib.pyplot as plt
          import warnings
          import mpld3
          import json
          import io
          import os
          from sklearn.ensemble import RandomForestClassifier
          from tensorflow.python.lib.io import file_io

          warnings.simplefilter(action="ignore", category=FutureWarning)
          warnings.simplefilter(action="ignore", category=UserWarning)

          os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/gcp_sa.json"

          with io.open("gcp_sa.json", "w", encoding="utf-8") as f:
              json.dump(in_gcp_sa_json, f, ensure_ascii=False)

          fs = gcsfs.GCSFileSystem(project=in_gcp_bucket_project)

          # include slash at the end of path
          if not in_gcp_bucket_output_path.endswith("/") : in_gcp_bucket_output_path+= "/";

          df = pd.read_csv(df_churn_ip)
          df1 = df.copy(deep=True)
          df1.to_csv(df_churn_op, index=False)

          sns.set(style="white")
          df["TotalCharges"] = df["TotalCharges"].replace(" ", 0).astype("float32")

          # Churn Plot
          ax = sns.catplot(
              y="Churn",
              kind="count",
              data=df,
              height=2.0,
              aspect=3.0,
              palette="bright",
              legend=True,
          )

          fig = plt.gcf()
          s = mpld3.fig_to_html(fig)

          with file_io.FileIO(in_gcp_bucket_output_path + "Graphs/churn_plot.html", "w") as f:
              f.write(s)

          def barplot_percentages(feature, orient="v", axis_name="percentage of customers"):
              ratios = pd.DataFrame()
              g = df.groupby(feature)["Churn"].value_counts().to_frame()
              g = g.rename({"Churn": axis_name}, axis=1).reset_index()
              g[axis_name] = g[axis_name] / len(df)
              if orient == "v":
                  ax = sns.barplot(
                      x=feature,
                      y=axis_name,
                      hue="Churn",
                      data=g,
                      orient=orient,
                      palette="bright",
                  )
                  ax.set_yticklabels(["{:,.0%}".format(y) for y in ax.get_yticks()])
              else:
                  ax = sns.barplot(
                      x=axis_name,
                      y=feature,
                      hue="Churn",
                      data=g,
                      orient=orient,
                      palette="bright",
                  )
                  ax.set_xticklabels(["{:,.0%}".format(x) for x in ax.get_xticks()])
              ax.plot()

          # Genders
          df["churn_rate"] = df["Churn"].replace("No", 0).replace("Yes", 1)
          g = sns.FacetGrid(df, col="SeniorCitizen", height=4, aspect=0.9)
          ax = g.map(
              sns.barplot, "gender", "churn_rate", palette="bright", order=["Female", "Male"]
          )

          fig = plt.gcf()
          s = mpld3.fig_to_html(fig)

          with file_io.FileIO(
              in_gcp_bucket_output_path + "Artifacts/Graphs/Genders.html", "w"
          ) as f:
              f.write(s)

          # Multiple Lines
          fig = plt.figure(figsize=(9, 4.5))
          barplot_percentages("MultipleLines", orient="v")

          fig = plt.gcf()
          s = mpld3.fig_to_html(fig)

          with file_io.FileIO(
              in_gcp_bucket_output_path + "Artifacts/Graphs/Multiple_lines.html", "w"
          ) as f:
              f.write(s)

          # Service-wise Columns analysis
          cols = [
              "OnlineSecurity",
              "OnlineBackup",
              "DeviceProtection",
              "TechSupport",
              "StreamingTV",
              "StreamingMovies",
          ]
          df1 = pd.melt(df[df["InternetService"] != "No"][cols]).rename(
              {"value": "Has service"}, axis=1
          )
          plt.figure(figsize=(10, 4.5))
          ax = sns.countplot(data=df1, x="variable", hue="Has service", palette="bright")
          ax.set(xlabel="Additional service", ylabel="Num of customers")

          fig = plt.gcf()

          s = mpld3.fig_to_html(fig)

          with file_io.FileIO(
              in_gcp_bucket_output_path + "Artifacts/Graphs/Servicewise_analysis.html", "w"
          ) as f:
              f.write(s)

          # Service-wise Columns analysis2
          plt.figure(figsize=(10, 4.5))
          df1 = df[(df.InternetService != "No") & (df.Churn == "Yes")]
          df1 = pd.melt(df1[cols]).rename({"value": "Has service"}, axis=1)
          ax = sns.countplot(
              data=df1,
              x="variable",
              hue="Has service",
              hue_order=["No", "Yes"],
              palette="bright",
          )
          ax.set(xlabel="Additional service", ylabel="Num of churns")

          fig = plt.gcf()
          s = mpld3.fig_to_html(fig)

          with file_io.FileIO(
              in_gcp_bucket_output_path + "Artifacts/Graphs/Servicewise_analysis2.html", "w"
          ) as f:
              f.write(s)

          # Generating Metadata
          metadata = {
              "version": 1,
              "outputs": [
                  {
                      "type": "web-app",
                      "storage": "gcs",
                      "source": in_gcp_bucket_output_path + "Artifacts/Graphs/churn_plot.html",
                  },
                  {
                      "type": "web-app",
                      "storage": "gcs",
                      "source": in_gcp_bucket_output_path + "Artifacts/Graphs/Genders.html",
                  },
                  {
                      "type": "web-app",
                      "storage": "gcs",
                      "source": in_gcp_bucket_output_path + "Artifacts/Graphs/Multiple_lines.html",
                  },
                  {
                      "type": "web-app",
                      "storage": "gcs",
                      "source": in_gcp_bucket_output_path + "Artifacts/Graphs/Servicewise_analysis.html",
                  },
                  {
                      "type": "web-app",
                      "storage": "gcs",
                      "source": in_gcp_bucket_output_path + "Artifacts/Graphs/Servicewise_analysis2.html",
                  },
              ],
          }

          with file_io.FileIO("/mlpipeline-ui-metadata.json", "w") as f:
              json.dump(metadata, f)

          with file_io.FileIO(mlpipeline_ui_metadata, "w") as f:
              json.dump(metadata, f)

      import json
      import argparse
      _parser = argparse.ArgumentParser(prog='Categorical analysis', description='')
      _parser.add_argument("--df-churn-ip", dest="df_churn_ip", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--in-gcp-bucket-project", dest="in_gcp_bucket_project", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--in-gcp-bucket-output-path", dest="in_gcp_bucket_output_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--in-gcp-sa-json", dest="in_gcp_sa_json", type=json.loads, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--mlpipeline-ui-metadata", dest="mlpipeline_ui_metadata", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--df-churn-op", dest="df_churn_op", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parsed_args = vars(_parser.parse_args())

      _outputs = categorical_analysis(**_parsed_args)
    args:
    - --df-churn-ip
    - {inputPath: df_churn_ip}
    - --in-gcp-bucket-project
    - {inputValue: in_gcp_bucket_project}
    - --in-gcp-bucket-output-path
    - {inputValue: in_gcp_bucket_output_path}
    - --in-gcp-sa-json
    - {inputValue: in_gcp_sa_json}
    - --mlpipeline-ui-metadata
    - {outputPath: mlpipeline_ui_metadata}
    - --df-churn-op
    - {outputPath: df_churn_op}
