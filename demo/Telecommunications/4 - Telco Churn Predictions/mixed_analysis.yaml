name: Mixed analysis
inputs:
- {name: df_churn_ip}
- {name: in_gcp_bucket_project, type: String}
- {name: in_gcp_bucket_output_path, type: String}
- {name: in_gcp_sa_json, type: JsonObject}
outputs:
- {name: mlpipeline_ui_metadata}
- {name: df_churn_op}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' 'gcsfs'
      'tensorflow==2.2.0' 'seaborn==0.9.0' 'matplotlib==3.1.1' 'mpld3==0.5.1' || PIP_DISABLE_PIP_VERSION_CHECK=1
      python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2'
      'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' 'gcsfs' 'tensorflow==2.2.0'
      'seaborn==0.9.0' 'matplotlib==3.1.1' 'mpld3==0.5.1' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def _make_parent_dirs_and_return_path(file_path: str):
          import os
          os.makedirs(os.path.dirname(file_path), exist_ok=True)
          return file_path

      def mixed_analysis(
          df_churn_ip,
          in_gcp_bucket_project,
          in_gcp_bucket_output_path,
          in_gcp_sa_json,
          mlpipeline_ui_metadata,
          df_churn_op,
      ):

          import pandas as pd
          import numpy as np
          import gcsfs
          import seaborn as sns
          import matplotlib.pyplot as plt
          import warnings
          import mpld3
          import json
          import io
          import os
          from sklearn.ensemble import RandomForestClassifier
          from tensorflow.python.lib.io import file_io

          warnings.simplefilter(action="ignore", category=FutureWarning)
          warnings.simplefilter(action="ignore", category=UserWarning)

          os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/gcp_sa.json"

          with io.open("gcp_sa.json", "w", encoding="utf-8") as f:
              json.dump(in_gcp_sa_json, f, ensure_ascii=False)

          fs = gcsfs.GCSFileSystem(project=in_gcp_bucket_project)

          # include slash at the end of path
          if not in_gcp_bucket_output_path.endswith("/") : in_gcp_bucket_output_path+= "/";

          df = pd.read_csv(df_churn_ip)

          df1 = df.copy(deep=True)
          df1.to_csv(df_churn_op, index=False)

          sns.set(style="white")
          df["TotalCharges"] = df["TotalCharges"].replace(" ", 0).astype("float32")

          df["total_charges_to_tenure_ratio"] = df["TotalCharges"] / df["tenure"]
          df["monthly_charges_diff"] = (
              df["MonthlyCharges"] - df["total_charges_to_tenure_ratio"]
          )
          df["churn_rate"] = df["Churn"].replace("No", 0).replace("Yes", 1)

          # Internet Service vs Monthly Charges
          ax = sns.catplot(
              x="InternetService",
              y="MonthlyCharges",
              hue="Churn",
              kind="violin",
              split=True,
              palette="pastel",
              data=df,
              height=4.2,
              aspect=1.4,
          )

          fig = plt.gcf()
          s = mpld3.fig_to_html(fig)

          with file_io.FileIO(
              in_gcp_bucket_output_path + "Artifacts/Graphs/violinplot2.html", "w"
          ) as f:
              f.write(s)

          metadata = {
              "version": 1,
              "outputs": [
                  {
                      "type": "web-app",
                      "storage": "gcs",
                      "source": in_gcp_bucket_output_path + "Artifacts/Graphs/violinplot2.html",
                  }
              ],
          }

          with file_io.FileIO("/mlpipeline-ui-metadata.json", "w") as f:
              json.dump(metadata, f)

          with file_io.FileIO(mlpipeline_ui_metadata, "w") as f:
              json.dump(metadata, f)

      import json
      import argparse
      _parser = argparse.ArgumentParser(prog='Mixed analysis', description='')
      _parser.add_argument("--df-churn-ip", dest="df_churn_ip", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--in-gcp-bucket-project", dest="in_gcp_bucket_project", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--in-gcp-bucket-output-path", dest="in_gcp_bucket_output_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--in-gcp-sa-json", dest="in_gcp_sa_json", type=json.loads, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--mlpipeline-ui-metadata", dest="mlpipeline_ui_metadata", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--df-churn-op", dest="df_churn_op", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parsed_args = vars(_parser.parse_args())

      _outputs = mixed_analysis(**_parsed_args)
    args:
    - --df-churn-ip
    - {inputPath: df_churn_ip}
    - --in-gcp-bucket-project
    - {inputValue: in_gcp_bucket_project}
    - --in-gcp-bucket-output-path
    - {inputValue: in_gcp_bucket_output_path}
    - --in-gcp-sa-json
    - {inputValue: in_gcp_sa_json}
    - --mlpipeline-ui-metadata
    - {outputPath: mlpipeline_ui_metadata}
    - --df-churn-op
    - {outputPath: df_churn_op}
