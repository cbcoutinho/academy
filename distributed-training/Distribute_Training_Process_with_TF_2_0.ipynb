{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distribute Training Process with TF 2.0",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cuX-NqLep7c",
        "colab_type": "text"
      },
      "source": [
        "First, we need to download the required libraries and the dataset we will be working on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo0PkLE-_wx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import TensorFlow and TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMJ0FImMAmsV",
        "colab_type": "code",
        "outputId": "f2b47dad-0c61-4544-db94-c2e926430c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uPcbCCGAp6g",
        "colab_type": "code",
        "outputId": "66698b98-be53-4b3c-cefc-772b353a5758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# Downloading the dataset \n",
        "datasets, info = tfds.load('beans', with_info=True, as_supervised=True)\n",
        "\n",
        "beans_train, beans_test = datasets['train'], datasets['test']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset beans/0.1.0 (download: Unknown size, generated: 171.63 MiB, total: 171.63 MiB) to /root/tensorflow_datasets/beans/0.1.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/beans/0.1.0.incompleteICDDYX/beans-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/beans/0.1.0.incompleteICDDYX/beans-validation.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/beans/0.1.0.incompleteICDDYX/beans-test.tfrecord\n",
            "\u001b[1mDataset beans downloaded and prepared to /root/tensorflow_datasets/beans/0.1.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMzJ9kBfe9BC",
        "colab_type": "text"
      },
      "source": [
        "### Now, some essential steps are required before we start our training. The hyperparameters need to be defined and more importantly, we need to initialize the distributed learning algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHH5B0cnBEsA",
        "colab_type": "code",
        "outputId": "a44057aa-9369-47ab-e834-61678e2f05c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Initializing the distributed learning algorithm\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9_MoBthBKxI",
        "colab_type": "code",
        "outputId": "4604ccc0-4adb-497e-8456-4d53d1ccd8dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Just checking the number of devices available for distributing\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI5geR7_BORX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining some hyperparameters\n",
        "num_train_examples = info.splits['train'].num_examples\n",
        "num_test_examples = info.splits['test'].num_examples\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 32\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwbYWERSBUk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing the pixel values\n",
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hKc2LxgBWaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batching the dataset and keeping a memory buffer for better performance\n",
        "train_dataset = beans_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = beans_test.map(scale).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6v1K-FiBYIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building our model\n",
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(16, 3, activation='relu', input_shape=(500, 500, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(3)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuzCUJe5BhNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the checkpoint directory to store the checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5IzP-2lBlTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "\n",
        "def decay(epoch):\n",
        "  if epoch < 3:\n",
        "    return 1e-3\n",
        "  elif epoch >= 3 and epoch < 7:\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kVkPaOIBnOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Callback for printing the LR at the end of each epoch.\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      model.optimizer.lr.numpy()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE4C0TiQBpTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining hte callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                       save_weights_only=True),\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
        "    PrintLR()\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH50NHXWBq_a",
        "colab_type": "code",
        "outputId": "0cbeeb35-38a7-40ad-9ba5-5021d2134776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "# Training the model\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "model.fit(train_dataset, epochs=10, callbacks=callbacks)\n",
        "end = time.time()\n",
        "print(\"Time elapsed: {}\".format(end-start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 1.4443 - accuracy: 0.5088\n",
            "Learning rate for epoch 1 is 0.0010000000474974513\n",
            "33/33 [==============================] - 3s 104ms/step - loss: 1.4237 - accuracy: 0.5097 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.7117 - accuracy: 0.7090\n",
            "Learning rate for epoch 2 is 0.0010000000474974513\n",
            "33/33 [==============================] - 3s 105ms/step - loss: 0.7054 - accuracy: 0.7099 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.5519 - accuracy: 0.7637\n",
            "Learning rate for epoch 3 is 0.0010000000474974513\n",
            "33/33 [==============================] - 3s 103ms/step - loss: 0.5604 - accuracy: 0.7621 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.4272 - accuracy: 0.8438\n",
            "Learning rate for epoch 4 is 9.999999747378752e-05\n",
            "33/33 [==============================] - 3s 105ms/step - loss: 0.4249 - accuracy: 0.8443 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.3595 - accuracy: 0.8711\n",
            "Learning rate for epoch 5 is 9.999999747378752e-05\n",
            "33/33 [==============================] - 3s 104ms/step - loss: 0.3642 - accuracy: 0.8704 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.8789\n",
            "Learning rate for epoch 6 is 9.999999747378752e-05\n",
            "33/33 [==============================] - 3s 103ms/step - loss: 0.3495 - accuracy: 0.8772 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.3212 - accuracy: 0.8857\n",
            "Learning rate for epoch 7 is 9.999999747378752e-05\n",
            "33/33 [==============================] - 3s 102ms/step - loss: 0.3189 - accuracy: 0.8859 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.2982 - accuracy: 0.9004\n",
            "Learning rate for epoch 8 is 9.999999747378752e-06\n",
            "33/33 [==============================] - 3s 105ms/step - loss: 0.2953 - accuracy: 0.9014 - lr: 1.0000e-05\n",
            "Epoch 9/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.2952 - accuracy: 0.9014\n",
            "Learning rate for epoch 9 is 9.999999747378752e-06\n",
            "33/33 [==============================] - 3s 102ms/step - loss: 0.2940 - accuracy: 0.9014 - lr: 1.0000e-05\n",
            "Epoch 10/10\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.9053\n",
            "Learning rate for epoch 10 is 9.999999747378752e-06\n",
            "33/33 [==============================] - 3s 103ms/step - loss: 0.2919 - accuracy: 0.9052 - lr: 1.0000e-05\n",
            "Time elapsed: 40.08736324310303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHLxDDFSe2CX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}