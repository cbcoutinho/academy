{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0eb9bfb6d2367f5ad13c071e9ca0a4847a6ac5b11a61adc2b39beabe858de7ad1",
   "display_name": "Python 3.7.9 64-bit ('ydata_tmp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Google Cloud Storage Connector - Quick Start\n",
    "\n",
    "The CGS connector enables you to read/write data within the Google Cloud Storage with ease and integrate it with YData's platform.\n",
    "Reading a dataset from GCS directly into a YData's `Dataset` allows its usage for Data Quality, Data Synthetisation and Preprocessing blocks.\n",
    "\n",
    "The following tutorial covers:\n",
    "- How to read data from GCS\n",
    "- How to read data (sample) from GCS\n",
    "- How to write data to GCS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "from ydata.connectors import GCSConnector\n",
    "from ydata.connectors.filetype import FileType\n",
    "from ydata.utils.formats import read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your credentials from a file\n",
    "token = read_json('../../.secrets/gcs_write_token.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/francisco/anaconda3/envs/ydata_tmp/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\nPerhaps you already have a cluster running?\nHosting the HTTP server on port 43297 instead\n  http_address[\"port\"], self.http_server.port\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Connector\n",
    "connector = GCSConnector(project_id=token['project_id'], keyfile_dict=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "My data is of type Dataset.\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset\n",
    "data = connector.read_file('gs://ydata_testdata/tabular/cardio/data.csv', file_type=FileType.CSV)\n",
    "print(f'My data is of type {type(data).__name__}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file_type argument is optional. If not provided, we will infer it from the path you have provided.\n",
    "parquet_data = connector.read_file('gs://ydata_testdata/tabular/data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a quick glimpse, we can load a small subset of the data (e.g. 1%)\n",
    "small_data = connector.read_sample('gs://ydata_testdata/tabular/data.parquet', sample_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could alternatively define a specific number of rows\n",
    "very_small_data = connector.read_sample('gs://ydata_testdata/tabular/data.parquet', sample_size=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of rows:\nOriginal: 70,000, \nSampled (%): 351\nSampled (n): 67.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Number of rows:\n",
    "Original: {data.shape[0]:,}, \n",
    "Sampled (%): {small_data.shape[0]:,}\n",
    "Sampled (n): {very_small_data.shape[0]:,}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/francisco/anaconda3/envs/ydata_tmp/lib/python3.7/site-packages/dask/dataframe/io/csv.py:815: UserWarning: Appending data to a network storage system may not work.\n  warn(\"Appending data to a network storage system may not work.\")\n"
     ]
    }
   ],
   "source": [
    "# Now imagine we want to store the sampled data.\n",
    "connector.write_file(small_data, 'gs://ydata_development/connectors/write_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/francisco/anaconda3/envs/ydata_tmp/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n  \n"
     ]
    }
   ],
   "source": [
    "# Alternatively, we can write a new Dataframe \n",
    "from pandas.util.testing import makeDataFrame\n",
    "dummy_df = makeDataFrame()\n",
    "connector.write_file(dummy_df, 'gs://ydata_development/connectors/write_sample.parquet', write_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we load the new dataset to ensure is working well\n",
    "dummy_data = connector.read_file('gs://ydata_development/connectors/write_sample.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   A         B         C         D\n",
       "vWR8EjvCN5 -1.080968  0.131254 -0.400662 -1.566470\n",
       "rgm3NTBIrg  1.343200  1.324647  0.064379 -1.756315\n",
       "CD9S1WB8sN -0.904694  0.222477 -0.174191 -0.815463\n",
       "zYSkrNk625 -0.874359 -0.287793 -0.876278 -0.081582\n",
       "JwxGp6cTn5 -0.100960 -0.016859 -0.799288  0.544344"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>vWR8EjvCN5</th>\n      <td>-1.080968</td>\n      <td>0.131254</td>\n      <td>-0.400662</td>\n      <td>-1.566470</td>\n    </tr>\n    <tr>\n      <th>rgm3NTBIrg</th>\n      <td>1.343200</td>\n      <td>1.324647</td>\n      <td>0.064379</td>\n      <td>-1.756315</td>\n    </tr>\n    <tr>\n      <th>CD9S1WB8sN</th>\n      <td>-0.904694</td>\n      <td>0.222477</td>\n      <td>-0.174191</td>\n      <td>-0.815463</td>\n    </tr>\n    <tr>\n      <th>zYSkrNk625</th>\n      <td>-0.874359</td>\n      <td>-0.287793</td>\n      <td>-0.876278</td>\n      <td>-0.081582</td>\n    </tr>\n    <tr>\n      <th>JwxGp6cTn5</th>\n      <td>-0.100960</td>\n      <td>-0.016859</td>\n      <td>-0.799288</td>\n      <td>0.544344</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# This is a sample from the new dataset's original data\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   A         B         C         D\n",
       "0G4d1A3oXF  0.559392  0.361695 -1.288391 -0.925004\n",
       "4uy2ackwkc -0.868865 -0.531903 -0.933147 -1.740783\n",
       "5ZjXiH4Whr  1.217328 -2.474033  0.653000  0.492108\n",
       "79nPY7QAc4  0.642221 -0.883361 -0.100726  0.429338\n",
       "9rT1iYFPo2 -0.318920  0.700615  0.130373  0.454638"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0G4d1A3oXF</th>\n      <td>0.559392</td>\n      <td>0.361695</td>\n      <td>-1.288391</td>\n      <td>-0.925004</td>\n    </tr>\n    <tr>\n      <th>4uy2ackwkc</th>\n      <td>-0.868865</td>\n      <td>-0.531903</td>\n      <td>-0.933147</td>\n      <td>-1.740783</td>\n    </tr>\n    <tr>\n      <th>5ZjXiH4Whr</th>\n      <td>1.217328</td>\n      <td>-2.474033</td>\n      <td>0.653000</td>\n      <td>0.492108</td>\n    </tr>\n    <tr>\n      <th>79nPY7QAc4</th>\n      <td>0.642221</td>\n      <td>-0.883361</td>\n      <td>-0.100726</td>\n      <td>0.429338</td>\n    </tr>\n    <tr>\n      <th>9rT1iYFPo2</th>\n      <td>-0.318920</td>\n      <td>0.700615</td>\n      <td>0.130373</td>\n      <td>0.454638</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# This is a sample from our \"stored-to-parquet-and-loaded\" data\n",
    "# The order of the rows may not match the original, given parallel-based way of reading and writing data.\n",
    "dummy_data.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All rows equal all columns in both datasets: True.\n"
     ]
    }
   ],
   "source": [
    "# But both datasets do match!\n",
    "print(f'All rows equal all columns in both datasets: {dummy_data.to_pandas().eq(dummy_df, axis=1).all(None)}.')"
   ]
  },
  {
   "source": [
    "## Advanced\n",
    "Advanced features enable you to manage Google Cloud Storage directly through the connector."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a specific blob\n",
    "# connector.delete_blob_if_exists('gs://ydata_development/connectors/write_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'files': [], 'dirs': ['connectors', 'issue#110']}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# List the contents under a given bucket\n",
    "connector.ls('gs://ydata_development/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'files': [('write_sample.csv', 31734)], 'dirs': ['write_sample.parquet']}"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# List the contents under a given bucket\n",
    "connector.ls('gs://ydata_development/connectors')"
   ]
  }
 ]
}