"apiVersion": |-
  argoproj.io/v1alpha1
"kind": |-
  Workflow
"metadata":
  "annotations":
    "pipelines.kubeflow.org/pipeline_spec": |-
      {"description": "Generates automatically a random key from a token based on Fibonacci sequences", "name": "Fibonacci Security Key Generator"}
  "generateName": |-
    fibonacci-security-key-generator-
"spec":
  "arguments":
    "parameters": []
  "entrypoint": |-
    fibonacci-security-key-generator
  "serviceAccountName": |-
    pipeline-runner
  "templates":
  - "dag":
      "tasks":
      - "arguments":
          "parameters":
          - "name": |-
              key-gen-2-outkey
            "value": |-
              {{tasks.key-gen-2.outputs.parameters.key-gen-2-outkey}}
          - "name": |-
              key-gen-token
            "value": |-
              {{tasks.key-gen.outputs.parameters.key-gen-token}}
        "dependencies":
        - |-
          key-gen
        - |-
          key-gen-2
        "name": |-
          key-decode
        "template": |-
          key-decode
      - "arguments":
          "parameters":
          - "name": |-
              key-gen-2-token
            "value": |-
              {{tasks.key-gen-2.outputs.parameters.key-gen-2-token}}
          - "name": |-
              key-gen-3-outkey
            "value": |-
              {{tasks.key-gen-3.outputs.parameters.key-gen-3-outkey}}
        "dependencies":
        - |-
          key-gen-2
        - |-
          key-gen-3
        "name": |-
          key-decode-2
        "template": |-
          key-decode-2
      - "arguments":
          "parameters":
          - "name": |-
              key-gen-2-outkey
            "value": |-
              {{tasks.key-gen-2.outputs.parameters.key-gen-2-outkey}}
          - "name": |-
              key-gen-3-token
            "value": |-
              {{tasks.key-gen-3.outputs.parameters.key-gen-3-token}}
        "dependencies":
        - |-
          key-gen-2
        - |-
          key-gen-3
        "name": |-
          key-decode-3
        "template": |-
          key-decode-3
      - "arguments":
          "parameters":
          - "name": |-
              token-generator-output
            "value": |-
              {{tasks.token-generator.outputs.parameters.token-generator-output}}
        "dependencies":
        - |-
          token-generator
        "name": |-
          key-gen
        "template": |-
          key-gen
      - "arguments":
          "parameters":
          - "name": |-
              token-generator-output
            "value": |-
              {{tasks.token-generator.outputs.parameters.token-generator-output}}
        "dependencies":
        - |-
          token-generator
        "name": |-
          key-gen-2
        "template": |-
          key-gen-2
      - "arguments":
          "parameters":
          - "name": |-
              token-generator-two-output
            "value": |-
              {{tasks.token-generator-two.outputs.parameters.token-generator-two-output}}
        "dependencies":
        - |-
          token-generator-two
        "name": |-
          key-gen-3
        "template": |-
          key-gen-3
      - "name": |-
          token-generator
        "template": |-
          token-generator
      - "name": |-
          token-generator-two
        "template": |-
          token-generator-two
    "name": |-
      fibonacci-security-key-generator
  - "container":
      "args":
      - |-
        --tok
      - |-
        {{inputs.parameters.key-gen-token}}
      - |-
        --seq-two
      - |-
        {{inputs.parameters.key-gen-2-outkey}}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/Output/data
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def key_decode(tok , seq_two ) :

            def fib_generate(a,s):
                p = 0
                q = s
                r = s
                for x in range(a-1):
                    r = p+q
                    p = q
                    q = r
                return r

            def fib_decode(f,s):
                x = 0
                y = fib_generate(0,s)
                while(f>=fib_generate(x,s)):
                    y = fib_generate(x,s)
                    x+=1
                return y

            if(fib_decode(seq_two, int(tok[0])+1)==seq_two):
                print("Keys match")
                out_str = "Keys Match"
            else:
                print("Keys don't match")
                out_str = "Keys Don't Match"

            return out_str

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Key decode', description='')
        _parser.add_argument("--tok", dest="tok", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--seq-two", dest="seq_two", type=int, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = key_decode(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "parameters":
      - "name": |-
          key-gen-2-outkey
      - "name": |-
          key-gen-token
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "tok", "type": "String"}, {"name": "seq_two", "type": "Integer"}], "name": "Key decode", "outputs": [{"name": "Output", "type": "String"}]}
    "name": |-
      key-decode
    "outputs":
      "artifacts":
      - "name": |-
          key-decode-output
        "path": |-
          /tmp/outputs/Output/data
  - "container":
      "args":
      - |-
        --tok
      - |-
        {{inputs.parameters.key-gen-2-token}}
      - |-
        --seq-two
      - |-
        {{inputs.parameters.key-gen-3-outkey}}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/Output/data
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def key_decode(tok , seq_two ) :

            def fib_generate(a,s):
                p = 0
                q = s
                r = s
                for x in range(a-1):
                    r = p+q
                    p = q
                    q = r
                return r

            def fib_decode(f,s):
                x = 0
                y = fib_generate(0,s)
                while(f>=fib_generate(x,s)):
                    y = fib_generate(x,s)
                    x+=1
                return y

            if(fib_decode(seq_two, int(tok[0])+1)==seq_two):
                print("Keys match")
                out_str = "Keys Match"
            else:
                print("Keys don't match")
                out_str = "Keys Don't Match"

            return out_str

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Key decode', description='')
        _parser.add_argument("--tok", dest="tok", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--seq-two", dest="seq_two", type=int, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = key_decode(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "parameters":
      - "name": |-
          key-gen-2-token
      - "name": |-
          key-gen-3-outkey
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "tok", "type": "String"}, {"name": "seq_two", "type": "Integer"}], "name": "Key decode", "outputs": [{"name": "Output", "type": "String"}]}
    "name": |-
      key-decode-2
    "outputs":
      "artifacts":
      - "name": |-
          key-decode-2-output
        "path": |-
          /tmp/outputs/Output/data
  - "container":
      "args":
      - |-
        --tok
      - |-
        {{inputs.parameters.key-gen-3-token}}
      - |-
        --seq-two
      - |-
        {{inputs.parameters.key-gen-2-outkey}}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/Output/data
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def key_decode(tok , seq_two ) :

            def fib_generate(a,s):
                p = 0
                q = s
                r = s
                for x in range(a-1):
                    r = p+q
                    p = q
                    q = r
                return r

            def fib_decode(f,s):
                x = 0
                y = fib_generate(0,s)
                while(f>=fib_generate(x,s)):
                    y = fib_generate(x,s)
                    x+=1
                return y

            if(fib_decode(seq_two, int(tok[0])+1)==seq_two):
                print("Keys match")
                out_str = "Keys Match"
            else:
                print("Keys don't match")
                out_str = "Keys Don't Match"

            return out_str

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Key decode', description='')
        _parser.add_argument("--tok", dest="tok", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--seq-two", dest="seq_two", type=int, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = key_decode(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "parameters":
      - "name": |-
          key-gen-2-outkey
      - "name": |-
          key-gen-3-token
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "tok", "type": "String"}, {"name": "seq_two", "type": "Integer"}], "name": "Key decode", "outputs": [{"name": "Output", "type": "String"}]}
    "name": |-
      key-decode-3
    "outputs":
      "artifacts":
      - "name": |-
          key-decode-3-output
        "path": |-
          /tmp/outputs/Output/data
  - "container":
      "args":
      - |-
        --tok
      - |-
        {{inputs.parameters.token-generator-output}}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/outkey/data
      - |-
        /tmp/outputs/token/data
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - "def key_gen(tok  )     :\n\n    tok = str(tok)\n\n    def fib_generate(a,s):\n\
        \        p = 0\n        q = s\n        r = s\n        for x in range(a-1):\n\
        \            r = p+q\n            p = q\n            q = r\n        return\
        \ r\n\n    out_key = fib_generate(int(str(tok[1])+str(tok[3])),int(tok[0])+1)\n\
        \    print(\"Generated key {}\".format(out_key))                        \n\
        \    return (out_key, tok)\n\ndef _serialize_int(int_value: int) -> str:\n\
        \    if isinstance(int_value, str):\n        return int_value\n    if not\
        \ isinstance(int_value, int):\n        raise TypeError('Value \"{}\" has type\
        \ \"{}\" instead of int.'.format(str(int_value), str(type(int_value))))\n\
        \    return str(int_value)\n\ndef _serialize_str(str_value: str) -> str:\n\
        \    if not isinstance(str_value, str):\n        raise TypeError('Value \"\
        {}\" has type \"{}\" instead of str.'.format(str(str_value), str(type(str_value))))\n\
        \    return str_value\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Key\
        \ gen', description='')\n_parser.add_argument(\"--tok\", dest=\"tok\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\"\
        , dest=\"_output_paths\", type=str, nargs=2)\n_parsed_args = vars(_parser.parse_args())\n\
        _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = key_gen(**_parsed_args)\n\
        \n_output_serializers = [\n    _serialize_int,\n    _serialize_str,\n\n]\n\
        \nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n\
        \        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
        \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "parameters":
      - "name": |-
          token-generator-output
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "tok", "type": "String"}], "name": "Key gen", "outputs": [{"name": "outkey", "type": "Integer"}, {"name": "token", "type": "String"}]}
    "name": |-
      key-gen
    "outputs":
      "artifacts":
      - "name": |-
          key-gen-outkey
        "path": |-
          /tmp/outputs/outkey/data
      - "name": |-
          key-gen-token
        "path": |-
          /tmp/outputs/token/data
      "parameters":
      - "name": |-
          key-gen-token
        "valueFrom":
          "path": |-
            /tmp/outputs/token/data
  - "container":
      "args":
      - |-
        --tok
      - |-
        {{inputs.parameters.token-generator-output}}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/outkey/data
      - |-
        /tmp/outputs/token/data
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - "def key_gen(tok  )     :\n\n    tok = str(tok)\n\n    def fib_generate(a,s):\n\
        \        p = 0\n        q = s\n        r = s\n        for x in range(a-1):\n\
        \            r = p+q\n            p = q\n            q = r\n        return\
        \ r\n\n    out_key = fib_generate(int(str(tok[1])+str(tok[3])),int(tok[0])+1)\n\
        \    print(\"Generated key {}\".format(out_key))                        \n\
        \    return (out_key, tok)\n\ndef _serialize_int(int_value: int) -> str:\n\
        \    if isinstance(int_value, str):\n        return int_value\n    if not\
        \ isinstance(int_value, int):\n        raise TypeError('Value \"{}\" has type\
        \ \"{}\" instead of int.'.format(str(int_value), str(type(int_value))))\n\
        \    return str(int_value)\n\ndef _serialize_str(str_value: str) -> str:\n\
        \    if not isinstance(str_value, str):\n        raise TypeError('Value \"\
        {}\" has type \"{}\" instead of str.'.format(str(str_value), str(type(str_value))))\n\
        \    return str_value\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Key\
        \ gen', description='')\n_parser.add_argument(\"--tok\", dest=\"tok\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\"\
        , dest=\"_output_paths\", type=str, nargs=2)\n_parsed_args = vars(_parser.parse_args())\n\
        _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = key_gen(**_parsed_args)\n\
        \n_output_serializers = [\n    _serialize_int,\n    _serialize_str,\n\n]\n\
        \nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n\
        \        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
        \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "parameters":
      - "name": |-
          token-generator-output
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "tok", "type": "String"}], "name": "Key gen", "outputs": [{"name": "outkey", "type": "Integer"}, {"name": "token", "type": "String"}]}
    "name": |-
      key-gen-2
    "outputs":
      "artifacts":
      - "name": |-
          key-gen-2-outkey
        "path": |-
          /tmp/outputs/outkey/data
      - "name": |-
          key-gen-2-token
        "path": |-
          /tmp/outputs/token/data
      "parameters":
      - "name": |-
          key-gen-2-outkey
        "valueFrom":
          "path": |-
            /tmp/outputs/outkey/data
      - "name": |-
          key-gen-2-token
        "valueFrom":
          "path": |-
            /tmp/outputs/token/data
  - "container":
      "args":
      - |-
        --tok
      - |-
        {{inputs.parameters.token-generator-two-output}}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/outkey/data
      - |-
        /tmp/outputs/token/data
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - "def key_gen(tok  )     :\n\n    tok = str(tok)\n\n    def fib_generate(a,s):\n\
        \        p = 0\n        q = s\n        r = s\n        for x in range(a-1):\n\
        \            r = p+q\n            p = q\n            q = r\n        return\
        \ r\n\n    out_key = fib_generate(int(str(tok[1])+str(tok[3])),int(tok[0])+1)\n\
        \    print(\"Generated key {}\".format(out_key))                        \n\
        \    return (out_key, tok)\n\ndef _serialize_int(int_value: int) -> str:\n\
        \    if isinstance(int_value, str):\n        return int_value\n    if not\
        \ isinstance(int_value, int):\n        raise TypeError('Value \"{}\" has type\
        \ \"{}\" instead of int.'.format(str(int_value), str(type(int_value))))\n\
        \    return str(int_value)\n\ndef _serialize_str(str_value: str) -> str:\n\
        \    if not isinstance(str_value, str):\n        raise TypeError('Value \"\
        {}\" has type \"{}\" instead of str.'.format(str(str_value), str(type(str_value))))\n\
        \    return str_value\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Key\
        \ gen', description='')\n_parser.add_argument(\"--tok\", dest=\"tok\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\"\
        , dest=\"_output_paths\", type=str, nargs=2)\n_parsed_args = vars(_parser.parse_args())\n\
        _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = key_gen(**_parsed_args)\n\
        \n_output_serializers = [\n    _serialize_int,\n    _serialize_str,\n\n]\n\
        \nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n\
        \        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
        \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "parameters":
      - "name": |-
          token-generator-two-output
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "tok", "type": "String"}], "name": "Key gen", "outputs": [{"name": "outkey", "type": "Integer"}, {"name": "token", "type": "String"}]}
    "name": |-
      key-gen-3
    "outputs":
      "artifacts":
      - "name": |-
          key-gen-3-outkey
        "path": |-
          /tmp/outputs/outkey/data
      - "name": |-
          key-gen-3-token
        "path": |-
          /tmp/outputs/token/data
      "parameters":
      - "name": |-
          key-gen-3-outkey
        "valueFrom":
          "path": |-
            /tmp/outputs/outkey/data
      - "name": |-
          key-gen-3-token
        "valueFrom":
          "path": |-
            /tmp/outputs/token/data
  - "container":
      "args":
      - |-
        ----output-paths
      - |-
        /tmp/outputs/Output/data
      "command":
      - |-
        sh
      - |-
        -c
      - |-
        (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'datetime' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'datetime' --user) && "$0" "$@"
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def token_generator()  :
            from datetime import datetime
            now = datetime.now()
            token = now.strftime("%H%M")
            while(len(token)<4):
                token = str(0)+str(token)
            return token

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Token generator', description='')
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = token_generator(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"name": "Token generator", "outputs": [{"name": "Output", "type": "String"}]}
    "name": |-
      token-generator
    "outputs":
      "artifacts":
      - "name": |-
          token-generator-output
        "path": |-
          /tmp/outputs/Output/data
      "parameters":
      - "name": |-
          token-generator-output
        "valueFrom":
          "path": |-
            /tmp/outputs/Output/data
  - "container":
      "args":
      - |-
        ----output-paths
      - |-
        /tmp/outputs/Output/data
      "command":
      - |-
        sh
      - |-
        -c
      - |-
        (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'datetime' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'datetime' --user) && "$0" "$@"
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def token_generator_two()  :
            from datetime import datetime
            now = datetime.now()
            token = now.strftime("%H%M")
            token = int(token)+7
            while(len(str(token))<4):
                token = str(0)+str(token)
            return str(token)

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Token generator two', description='')
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = token_generator_two(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"name": "Token generator two", "outputs": [{"name": "Output", "type": "String"}]}
    "name": |-
      token-generator-two
    "outputs":
      "artifacts":
      - "name": |-
          token-generator-two-output
        "path": |-
          /tmp/outputs/Output/data
      "parameters":
      - "name": |-
          token-generator-two-output
        "valueFrom":
          "path": |-
            /tmp/outputs/Output/data
