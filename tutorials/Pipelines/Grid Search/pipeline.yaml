"apiVersion": |-
  argoproj.io/v1alpha1
"kind": |-
  Workflow
"metadata":
  "annotations":
    "pipelines.kubeflow.org/pipeline_spec": |-
      {"description": "Run Grid-search on all 3 models for best input Parameters", "inputs": [{"default": "gs://pipelines_artifacts/Artifacts/Data.csv", "name": "file_path", "optional": true}], "name": "Grid Search Pipeline"}
  "generateName": |-
    grid-search-pipeline-
"spec":
  "arguments":
    "parameters":
    - "name": |-
        file_path
      "value": |-
        gs://pipelines_artifacts/Artifacts/Data.csv
  "entrypoint": |-
    grid-search-pipeline
  "serviceAccountName": |-
    pipeline-runner
  "templates":
  - "dag":
      "tasks":
      - "arguments":
          "artifacts":
          - "from": |-
              {{tasks.one-hot-encode.outputs.artifacts.one-hot-encode-df_one_hot}}
            "name": |-
              one-hot-encode-df_one_hot
        "dependencies":
        - |-
          one-hot-encode
        "name": |-
          gridsearch
        "template": |-
          gridsearch
      - "arguments":
          "artifacts":
          - "from": |-
              {{tasks.one-hot-encode.outputs.artifacts.one-hot-encode-df_one_hot}}
            "name": |-
              one-hot-encode-df_one_hot
        "dependencies":
        - |-
          one-hot-encode
        "name": |-
          gridsearch-2
        "template": |-
          gridsearch-2
      - "arguments":
          "artifacts":
          - "from": |-
              {{tasks.one-hot-encode.outputs.artifacts.one-hot-encode-df_one_hot}}
            "name": |-
              one-hot-encode-df_one_hot
        "dependencies":
        - |-
          one-hot-encode
        "name": |-
          gridsearch-3
        "template": |-
          gridsearch-3
      - "arguments":
          "artifacts":
          - "from": |-
              {{tasks.read-data.outputs.artifacts.read-data-df_churn_op}}
            "name": |-
              read-data-df_churn_op
        "dependencies":
        - |-
          read-data
        "name": |-
          one-hot-encode
        "template": |-
          one-hot-encode
      - "arguments":
          "parameters":
          - "name": |-
              file_path
            "value": |-
              {{inputs.parameters.file_path}}
        "name": |-
          read-data
        "template": |-
          read-data
      - "arguments":
          "artifacts":
          - "from": |-
              {{tasks.one-hot-encode.outputs.artifacts.one-hot-encode-df_one_hot}}
            "name": |-
              one-hot-encode-df_one_hot
          "parameters":
          - "name": |-
              gridsearch-output
            "value": |-
              {{tasks.gridsearch.outputs.parameters.gridsearch-output}}
        "dependencies":
        - |-
          gridsearch
        - |-
          one-hot-encode
        "name": |-
          rf-model
        "template": |-
          rf-model
      - "arguments":
          "artifacts":
          - "from": |-
              {{tasks.one-hot-encode.outputs.artifacts.one-hot-encode-df_one_hot}}
            "name": |-
              one-hot-encode-df_one_hot
          "parameters":
          - "name": |-
              gridsearch-2-output
            "value": |-
              {{tasks.gridsearch-2.outputs.parameters.gridsearch-2-output}}
        "dependencies":
        - |-
          gridsearch-2
        - |-
          one-hot-encode
        "name": |-
          xgb-model
        "template": |-
          xgb-model
    "inputs":
      "parameters":
      - "name": |-
          file_path
    "name": |-
      grid-search-pipeline
  - "container":
      "args":
      - |-
        --df-churn-ip
      - |-
        /tmp/inputs/df_churn_ip/data
      - |-
        --model
      - |-
        RandomForest
      - |-
        --parameters
      - |-
        {"max_depth": [10, 30, 100], "max_features": [2, 3], "min_samples_leaf": [3, 4, 5], "criterion": ["gini"], "min_samples_split": [2, 3, 4], "n_estimators": [100, 200, 300, 1000]}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/Output/data
      "command":
      - |-
        sh
      - |-
        -c
      - |-
        (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' --user) && "$0" "$@"
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def gridsearch(df_churn_ip , model , parameters )  :
            import pandas as pd
            import numpy as np
            import sklearn

            from sklearn.ensemble import RandomForestClassifier
            from sklearn.linear_model import LogisticRegression
            import xgboost as xgb

            from sklearn.preprocessing import StandardScaler
            from sklearn.model_selection import train_test_split, GridSearchCV
            from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, f1_score

            df_churn = pd.read_csv(df_churn_ip)
            df_churn.dropna(inplace=True)

            y1 = df_churn['Churn']
            X1 = df_churn.drop(['Churn'],axis=1)
            X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)

            if(model=='RandomForest'):
                clf = RandomForestClassifier()

            elif(model=='XGBoost'):
                clf = xgb.XGBClassifier()

            elif(model=='XGBoostRF'):
                clf = xgb.XGBRFClassifier()

            gscv = GridSearchCV(estimator=clf, param_grid=parameters, cv = 4, n_jobs = -1, verbose = 0)
            gscv.fit(X_train, y_train)

            best_params = gscv.best_params_

            print('Best Parameters: {}\n'.format(best_params))
            best_grid = gscv.best_estimator_
            print('Train Score: {}\n'.format(gscv.best_score_))

            test_accuracy = gscv.score(X_test, y_test)
            print('Test score: {}'.format(test_accuracy))

            return best_params

        def _serialize_json(obj) -> str:
            if isinstance(obj, str):
                return obj
            import json
            def default_serializer(obj):
                if hasattr(obj, 'to_struct'):
                    return obj.to_struct()
                else:
                    raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
            return json.dumps(obj, default=default_serializer)

        import json
        import argparse
        _parser = argparse.ArgumentParser(prog='Gridsearch', description='')
        _parser.add_argument("--df-churn-ip", dest="df_churn_ip", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model", dest="model", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--parameters", dest="parameters", type=json.loads, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = gridsearch(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_json,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "artifacts":
      - "name": |-
          one-hot-encode-df_one_hot
        "path": |-
          /tmp/inputs/df_churn_ip/data
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "df_churn_ip"}, {"name": "model", "type": "String"}, {"name": "parameters", "type": "JsonObject"}], "name": "Gridsearch", "outputs": [{"name": "Output", "type": "JsonObject"}]}
    "name": |-
      gridsearch
    "outputs":
      "artifacts":
      - "name": |-
          gridsearch-output
        "path": |-
          /tmp/outputs/Output/data
      "parameters":
      - "name": |-
          gridsearch-output
        "valueFrom":
          "path": |-
            /tmp/outputs/Output/data
  - "container":
      "args":
      - |-
        --df-churn-ip
      - |-
        /tmp/inputs/df_churn_ip/data
      - |-
        --model
      - |-
        XGBoost
      - |-
        --parameters
      - |-
        {"n_estimators": [100, 200, 300, 1000], "verbosity": [0], "max_depth": [10, 30, 100], "eta": [1], "silent": [0]}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/Output/data
      "command":
      - |-
        sh
      - |-
        -c
      - |-
        (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' --user) && "$0" "$@"
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def gridsearch(df_churn_ip , model , parameters )  :
            import pandas as pd
            import numpy as np
            import sklearn

            from sklearn.ensemble import RandomForestClassifier
            from sklearn.linear_model import LogisticRegression
            import xgboost as xgb

            from sklearn.preprocessing import StandardScaler
            from sklearn.model_selection import train_test_split, GridSearchCV
            from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, f1_score

            df_churn = pd.read_csv(df_churn_ip)
            df_churn.dropna(inplace=True)

            y1 = df_churn['Churn']
            X1 = df_churn.drop(['Churn'],axis=1)
            X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)

            if(model=='RandomForest'):
                clf = RandomForestClassifier()

            elif(model=='XGBoost'):
                clf = xgb.XGBClassifier()

            elif(model=='XGBoostRF'):
                clf = xgb.XGBRFClassifier()

            gscv = GridSearchCV(estimator=clf, param_grid=parameters, cv = 4, n_jobs = -1, verbose = 0)
            gscv.fit(X_train, y_train)

            best_params = gscv.best_params_

            print('Best Parameters: {}\n'.format(best_params))
            best_grid = gscv.best_estimator_
            print('Train Score: {}\n'.format(gscv.best_score_))

            test_accuracy = gscv.score(X_test, y_test)
            print('Test score: {}'.format(test_accuracy))

            return best_params

        def _serialize_json(obj) -> str:
            if isinstance(obj, str):
                return obj
            import json
            def default_serializer(obj):
                if hasattr(obj, 'to_struct'):
                    return obj.to_struct()
                else:
                    raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
            return json.dumps(obj, default=default_serializer)

        import json
        import argparse
        _parser = argparse.ArgumentParser(prog='Gridsearch', description='')
        _parser.add_argument("--df-churn-ip", dest="df_churn_ip", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model", dest="model", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--parameters", dest="parameters", type=json.loads, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = gridsearch(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_json,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "artifacts":
      - "name": |-
          one-hot-encode-df_one_hot
        "path": |-
          /tmp/inputs/df_churn_ip/data
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "df_churn_ip"}, {"name": "model", "type": "String"}, {"name": "parameters", "type": "JsonObject"}], "name": "Gridsearch", "outputs": [{"name": "Output", "type": "JsonObject"}]}
    "name": |-
      gridsearch-2
    "outputs":
      "artifacts":
      - "name": |-
          gridsearch-2-output
        "path": |-
          /tmp/outputs/Output/data
      "parameters":
      - "name": |-
          gridsearch-2-output
        "valueFrom":
          "path": |-
            /tmp/outputs/Output/data
  - "container":
      "args":
      - |-
        --df-churn-ip
      - |-
        /tmp/inputs/df_churn_ip/data
      - |-
        --model
      - |-
        XGBoostRF
      - |-
        --parameters
      - |-
        {"n_estimators": [100, 200, 300, 1000], "verbosity": [0], "max_depth": [10, 30, 100], "eta": [1], "silent": [0]}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/Output/data
      "command":
      - |-
        sh
      - |-
        -c
      - |-
        (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' --user) && "$0" "$@"
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        def gridsearch(df_churn_ip , model , parameters )  :
            import pandas as pd
            import numpy as np
            import sklearn

            from sklearn.ensemble import RandomForestClassifier
            from sklearn.linear_model import LogisticRegression
            import xgboost as xgb

            from sklearn.preprocessing import StandardScaler
            from sklearn.model_selection import train_test_split, GridSearchCV
            from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, f1_score

            df_churn = pd.read_csv(df_churn_ip)
            df_churn.dropna(inplace=True)

            y1 = df_churn['Churn']
            X1 = df_churn.drop(['Churn'],axis=1)
            X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)

            if(model=='RandomForest'):
                clf = RandomForestClassifier()

            elif(model=='XGBoost'):
                clf = xgb.XGBClassifier()

            elif(model=='XGBoostRF'):
                clf = xgb.XGBRFClassifier()

            gscv = GridSearchCV(estimator=clf, param_grid=parameters, cv = 4, n_jobs = -1, verbose = 0)
            gscv.fit(X_train, y_train)

            best_params = gscv.best_params_

            print('Best Parameters: {}\n'.format(best_params))
            best_grid = gscv.best_estimator_
            print('Train Score: {}\n'.format(gscv.best_score_))

            test_accuracy = gscv.score(X_test, y_test)
            print('Test score: {}'.format(test_accuracy))

            return best_params

        def _serialize_json(obj) -> str:
            if isinstance(obj, str):
                return obj
            import json
            def default_serializer(obj):
                if hasattr(obj, 'to_struct'):
                    return obj.to_struct()
                else:
                    raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
            return json.dumps(obj, default=default_serializer)

        import json
        import argparse
        _parser = argparse.ArgumentParser(prog='Gridsearch', description='')
        _parser.add_argument("--df-churn-ip", dest="df_churn_ip", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model", dest="model", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--parameters", dest="parameters", type=json.loads, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = gridsearch(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_json,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "artifacts":
      - "name": |-
          one-hot-encode-df_one_hot
        "path": |-
          /tmp/inputs/df_churn_ip/data
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "df_churn_ip"}, {"name": "model", "type": "String"}, {"name": "parameters", "type": "JsonObject"}], "name": "Gridsearch", "outputs": [{"name": "Output", "type": "JsonObject"}]}
    "name": |-
      gridsearch-3
    "outputs":
      "artifacts":
      - "name": |-
          gridsearch-3-output
        "path": |-
          /tmp/outputs/Output/data
  - "container":
      "args":
      - |-
        --df-churn-ip
      - |-
        /tmp/inputs/df_churn_ip/data
      - |-
        --df-one-hot
      - |-
        /tmp/outputs/df_one_hot/data
      "command":
      - |-
        sh
      - |-
        -c
      - |-
        (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'imbalanced-learn==0.6.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'imbalanced-learn==0.6.2' --user) && "$0" "$@"
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n \
        \   os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\
        \ndef one_hot_encode(df_churn_ip , df_one_hot ):\n\n    import pandas as pd\n\
        \    import numpy as np\n\n    df_churn = pd.read_csv(df_churn_ip)\n    empty_cols\
        \ = ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n \
        \          'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n\
        \           'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport',\n\
        \           'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n\
        \           'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n\n\
        \    #Replacing Empty values\n    for i in empty_cols:\n        df_churn[i]=df_churn[i].replace(\"\
        \ \",np.nan)\n\n    df_churn.drop(['customerID'], axis=1, inplace=True)\n\
        \    df_churn = df_churn.dropna()\n    binary_cols = ['Partner','Dependents','PhoneService','PaperlessBilling']\n\
        \n    #Binary Encoding\n    for i in binary_cols:\n        df_churn[i] = df_churn[i].replace({\"\
        Yes\":1,\"No\":0})\n\n    #Encoding column 'gender'\n    df_churn['gender']\
        \ = df_churn['gender'].replace({\"Male\":1,\"Female\":0})\n\n    category_cols\
        \ = ['PaymentMethod','MultipleLines','InternetService','OnlineSecurity',\n\
        \                   'OnlineBackup','DeviceProtection',\n                 \
        \  'TechSupport','StreamingTV','StreamingMovies','Contract']\n\n    #One-hot\
        \ Encoding of multiple-category columns\n    for cc in category_cols:\n  \
        \      dummies = pd.get_dummies(df_churn[cc], drop_first=False)\n        dummies\
        \ = dummies.add_prefix(\"{}#\".format(cc))\n        df_churn.drop(cc, axis=1,\
        \ inplace=True)\n        df_churn = df_churn.join(dummies)\n\n    df_churn_targets\
        \ = df_churn['Churn'].unique()\n    df_churn['Churn'] = df_churn['Churn'].replace({\"\
        Yes\":1,\"No\":0})\n\n    #Output the encoded file \n    df_churn.to_csv(df_one_hot,\
        \ index=False)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='One\
        \ hot encode', description='')\n_parser.add_argument(\"--df-churn-ip\", dest=\"\
        df_churn_ip\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --df-one-hot\", dest=\"df_one_hot\", type=_make_parent_dirs_and_return_path,\
        \ required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
        _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = one_hot_encode(**_parsed_args)\n\
        \n_output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
        \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
        \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "artifacts":
      - "name": |-
          read-data-df_churn_op
        "path": |-
          /tmp/inputs/df_churn_ip/data
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "df_churn_ip"}], "name": "One hot encode", "outputs": [{"name": "df_one_hot"}]}
    "name": |-
      one-hot-encode
    "outputs":
      "artifacts":
      - "name": |-
          one-hot-encode-df_one_hot
        "path": |-
          /tmp/outputs/df_one_hot/data
  - "container":
      "args":
      - |-
        --file-name
      - |-
        {{inputs.parameters.file_path}}
      - |-
        --df-churn-op
      - |-
        /tmp/outputs/df_churn_op/data
      - |-
        --mlpipeline-ui-metadata
      - |-
        /tmp/outputs/mlpipeline_ui_metadata/data
      "command":
      - |-
        sh
      - |-
        -c
      - |-
        (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'numpy==1.17.2' 'pandas==1.0.3' 'gcsfs' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'numpy==1.17.2' 'pandas==1.0.3' 'gcsfs' --user) && "$0" "$@"
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n \
        \   os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\
        \ndef read_data(file_name , df_churn_op , mlpipeline_ui_metadata ): \n\n \
        \   ## Import Required Libraries\n    import pandas as pd\n    import numpy\
        \ as np\n    import gcsfs\n    from tensorflow.python.lib.io import file_io\n\
        \    import json\n\n    fs = gcsfs.GCSFileSystem(project='YDataSynthetic',\
        \ token = 'cloud')\n\n    df_churn = pd.read_csv(file_name)\n    df_churn.to_csv(df_churn_op,\
        \ index=False)\n\n    df_disp = df_churn.iloc[0:5]\n    df_disp = df_disp[['customerID','gender','tenure','Contract','TotalCharges','Churn']]\n\
        \n    df_disp.to_csv('gs://pipelines_artifacts/Artifacts/Data_Sample.csv',\
        \ index=False)\n\n    df_show = pd.read_csv(\"gs://pipelines_artifacts/Artifacts/Data_Sample.csv\"\
        )\n    categorical_cols = [c for c in df_show.columns if df_show[c].dtype\
        \ == 'object' or c == 'SeniorCitizen']\n\n    numerical_cols = ['tenure',\
        \ 'MonthlyCharges', 'TotalCharges']\n\n    schema = [{'name':c, 'type': 'CATEGORY'if\
        \ c in categorical_cols else 'NUMBER'} for c in df_show.columns]\n\n    metadata\
        \ = {\n        'outputs' : [{\n          'type': 'table',\n          'storage':\
        \ 'gcs',\n          'format': 'csv',\n          'header': [x['name'] for x\
        \ in schema],\n          'source': 'gs://pipelines_artifacts/Artifacts/Data_Sample.csv'\n\
        \        }\n        ]\n    }\n\n    with file_io.FileIO('/mlpipeline-ui-metadata.json',\
        \ 'w') as f:\n        json.dump(metadata, f)\n\n    with file_io.FileIO(mlpipeline_ui_metadata,\
        \ 'w') as f:\n        json.dump(metadata, f)\n\nimport argparse\n_parser =\
        \ argparse.ArgumentParser(prog='Read data', description='')\n_parser.add_argument(\"\
        --file-name\", dest=\"file_name\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--df-churn-op\", dest=\"df_churn_op\", type=_make_parent_dirs_and_return_path,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--mlpipeline-ui-metadata\"\
        , dest=\"mlpipeline_ui_metadata\", type=_make_parent_dirs_and_return_path,\
        \ required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
        _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = read_data(**_parsed_args)\n\
        \n_output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
        \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
        \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "parameters":
      - "name": |-
          file_path
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "file_name", "type": "String"}], "name": "Read data", "outputs": [{"name": "df_churn_op"}, {"name": "mlpipeline_ui_metadata"}]}
    "name": |-
      read-data
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /tmp/outputs/mlpipeline_ui_metadata/data
      - "name": |-
          read-data-df_churn_op
        "path": |-
          /tmp/outputs/df_churn_op/data
  - "container":
      "args":
      - |-
        --df-churn-ip
      - |-
        /tmp/inputs/df_churn_ip/data
      - |-
        --parameters
      - |-
        {{inputs.parameters.gridsearch-output}}
      - |-
        --conf-matr
      - |-
        /tmp/outputs/conf_matr/data
      - |-
        --mlpipeline-ui-metadata
      - |-
        /tmp/outputs/mlpipeline_ui_metadata/data
      - |-
        --mlpipeline-metrics
      - |-
        /tmp/outputs/mlpipeline_metrics/data
      "command":
      - |-
        sh
      - |-
        -c
      - |-
        (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'gcsfs' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'gcsfs' --user) && "$0" "$@"
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n \
        \   os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\
        \ndef rf_model(df_churn_ip , parameters ,\n              conf_matr ,\n   \
        \           mlpipeline_ui_metadata , mlpipeline_metrics ):\n\n    import pandas\
        \ as pd\n    import numpy as np\n    import sklearn\n    from sklearn.ensemble\
        \ import RandomForestClassifier\n    from sklearn.model_selection import train_test_split\n\
        \    from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score,\
        \ roc_curve, precision_score, recall_score, f1_score\n    import json\n  \
        \  import os\n    import gcsfs\n    from tensorflow.python.lib.io import file_io\n\
        \n    df_churn = pd.read_csv(df_churn_ip)\n    df_churn.dropna(inplace=True)\n\
        \n    y1 = df_churn['Churn']\n    X1 = df_churn.drop(['Churn'],axis=1)\n\n\
        \    #Split Data into training and testing sets\n    X_train, X_test, y_train,\
        \ y_test = train_test_split(X1, y1, random_state=0)\n\n    #fit the model\
        \ on the Data and train it\n    rfc_best = RandomForestClassifier(**parameters)\n\
        \n    rfc_best.fit(X_train, y_train) \n    y_test_pred = rfc_best.predict(X_test)\n\
        \    y_test_proba = rfc_best.predict_proba(X_test)[:,0]\n\n    #Get Metrics\
        \ scores\n\n    rf_score = float('%.4f' %rfc_best.score(X_test, y_test)) \
        \  \n    rf_precision = float('%.4f' %precision_score(y_test, y_test_pred))\n\
        \    rf_recall = float('%.4f' %recall_score(y_test, y_test_pred))\n    rf_f1\
        \ = float('%.4f' %f1_score(y_test, y_test_pred))\n\n    print(\"Accuraccy,\
        \ Precision, Recall, f1: \")\n    print(rf_score, rf_precision, rf_recall,\
        \ rf_f1)\n\n    #Confusion Matrix\n    cm = confusion_matrix(y_test, y_test_pred)\n\
        \    print(\"Confusion Matrix: {}\".format(cm))\n\n    #True and False Positive\
        \ Rates\n    fpr, tpr, thresholds = roc_curve(y_test, y_test_proba) \n   \
        \ auc_score = float('%.4f' %roc_auc_score(y_test, y_test_proba))\n    print('Auc\
        \ score: ')\n    print(auc_score)\n\n    #Converting the Confusion matrix\
        \ to a Dataframe\n    #Note that for Generating the Confusion Matrix Artifact,\
        \ the Confusion Matrix has to be converted from\n    #a numpy array to a DataFrame\
        \ in the exact format as given below\n\n    flags = {0:'Not Churned',1:'Churned'}\n\
        \    flag_list = ['Not Churned','Churned']\n    data = []\n    for target_index,\
        \ target_row in enumerate(cm):\n        for predicted_index, count in enumerate(target_row):\n\
        \            data.append((flags[target_index], flags[predicted_index], count))\n\
        \n    df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])\n\
        \    print(df_cm)\n\n    with file_io.FileIO(conf_matr, 'w') as f:\n     \
        \   df_cm.to_csv(f, columns=['target', 'predicted', 'count'], header=False,\
        \ index=False)\n\n    fs = gcsfs.GCSFileSystem(project='YDataSynthetic', token\
        \ = 'cloud')\n\n    #Save confusion Matrix to GCS\n    with file_io.FileIO('gs://pipelines_artifacts/Artifacts/Conf_matRF.csv',\
        \ 'w') as f:\n        df_cm.to_csv(f, columns=['target', 'predicted', 'count'],\
        \ header=False, index=False)\n\n    #roc curve\n    #For generating the ROC\
        \ curve, the tpr, fpr and thresholds need to be output as a DataFrame in the\
        \ \n    #exact format as given below\n\n    df_roc = pd.DataFrame({'fpr':\
        \ fpr, 'tpr': tpr, 'thresholds': thresholds})\n    with file_io.FileIO('gs://pipelines_artifacts/Artifacts/ROC_curveRF.csv',\
        \ 'w') as f:\n        df_roc.to_csv(f, columns=['fpr', 'tpr', 'thresholds'],\
        \ header=False, index=False)\n\n    #code to generate artifacts\n\n    #Artifact\
        \ generator - metadata\n\n    from tensorflow.python.lib.io import file_io\n\
        \    import json\n\n    metadata = {\n        'version' : 1, \n        'outputs'\
        \ : [{\n            'type': 'confusion_matrix',\n            'format': 'csv',\n\
        \            'storage': 'gcs',\n            'schema': [   #schema is required\
        \ in the exact same form for generating the artifact\n                {'name':\
        \ 'target', 'type': 'CATEGORY'},\n                {'name': 'predicted', 'type':\
        \ 'CATEGORY'},\n                {'name': 'count', 'type': 'NUMBER'},\n   \
        \         ],\n            'source': 'gs://pipelines_artifacts/Artifacts/Conf_matRF.csv',\
        \ #conf_matr\n\n       # Convert flags to string because for bealean values\
        \ we want \"True|False\" to match csv data.\n            'labels': flag_list\n\
        \        },    \n        {\n          'type': 'roc',\n          'format':\
        \ 'csv',\n          'storage': 'gcs',\n          'schema': [  #schema is required\
        \ in the exact same form for generating the artifact\n            {'name':\
        \ 'fpr', 'type': 'NUMBER'},\n            {'name': 'tpr', 'type': 'NUMBER'},\n\
        \            {'name': 'thresholds', 'type': 'NUMBER'},\n          ],\n   \
        \       'source': 'gs://pipelines_artifacts/Artifacts/ROC_curveRF.csv'\n \
        \       }\n        ]\n    }\n\n    #Output the file to the container-level\
        \ root with the exact same name as below \n    with file_io.FileIO('/mlpipeline-ui-metadata.json',\
        \ 'w') as f:\n        json.dump(metadata, f)\n\n    #Also output to Minio\
        \ \n    with file_io.FileIO(mlpipeline_ui_metadata, 'w') as f:\n        json.dump(metadata,\
        \ f)\n\n    #The metric scores can output as Pipeline Metrics by generating\
        \ a json file as below\n    metrics = {\n    'metrics': [{\n      'name':\
        \ 'accuracy-score', # The name of the metric. Visualized as the column name\
        \ in the runs table.\n      'numberValue':  rf_score, # The value of the metric.\
        \ Must be a numeric value.\n      'format': \"RAW\",   # The optional format\
        \ of the metric. Supported values are \"RAW\" (displayed in raw format) \n\
        \                            # and \"PERCENTAGE\" (displayed in percentage\
        \ format).\n    },\n    {\n      'name': 'precision-score', # The name of\
        \ the metric. Visualized as the column name in the runs table.\n      'numberValue':\
        \  rf_precision, # The value of the metric. Must be a numeric value.\n   \
        \   'format': \"RAW\",   # The optional format of the metric. Supported values\
        \ are \"RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage\
        \ format).\n    },\n    {\n      'name': 'recall', # The name of the metric.\
        \ Visualized as the column name in the runs table.\n      'numberValue': \
        \ rf_recall, # The value of the metric. Must be a numeric value.\n      'format':\
        \ \"RAW\",   # The optional format of the metric. Supported values are \"\
        RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage\
        \ format).\n    },\n    {\n      'name': 'f1-score', # The name of the metric.\
        \ Visualized as the column name in the runs table.\n      'numberValue': \
        \ rf_f1, # The value of the metric. Must be a numeric value.\n      'format':\
        \ \"RAW\",   # The optional format of the metric. Supported values are \"\
        RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage\
        \ format).\n    },\n    {\n      'name': 'auc-score', # The name of the metric.\
        \ Visualized as the column name in the runs table.\n      'numberValue': \
        \ auc_score, # The value of the metric. Must be a numeric value.\n      'format':\
        \ \"RAW\",   # The optional format of the metric. Supported values are \"\
        RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage\
        \ format).\n    }]\n    }\n\n    #Dump the metrics json file with the exact\
        \ same name to the container-root directory\n    with file_io.FileIO('/mlpipeline-metrics.json',\
        \ 'w') as f:\n        json.dump(metrics, f)\n\n    #Also dump it to the Minio\
        \ file storage\n    with file_io.FileIO(mlpipeline_metrics, 'w') as f:\n \
        \       json.dump(metrics, f)\n\nimport json\nimport argparse\n_parser = argparse.ArgumentParser(prog='Rf\
        \ model', description='')\n_parser.add_argument(\"--df-churn-ip\", dest=\"\
        df_churn_ip\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --parameters\", dest=\"parameters\", type=json.loads, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--conf-matr\", dest=\"conf_matr\", type=_make_parent_dirs_and_return_path,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--mlpipeline-ui-metadata\"\
        , dest=\"mlpipeline_ui_metadata\", type=_make_parent_dirs_and_return_path,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--mlpipeline-metrics\"\
        , dest=\"mlpipeline_metrics\", type=_make_parent_dirs_and_return_path, required=True,\
        \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
        _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = rf_model(**_parsed_args)\n\
        \n_output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
        \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
        \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "artifacts":
      - "name": |-
          one-hot-encode-df_one_hot
        "path": |-
          /tmp/inputs/df_churn_ip/data
      "parameters":
      - "name": |-
          gridsearch-output
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "df_churn_ip"}, {"name": "parameters", "type": "JsonObject"}], "name": "Rf model", "outputs": [{"name": "conf_matr"}, {"name": "mlpipeline_ui_metadata"}, {"name": "mlpipeline_metrics"}]}
    "name": |-
      rf-model
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /tmp/outputs/mlpipeline_ui_metadata/data
      - "name": |-
          mlpipeline-metrics
        "path": |-
          /tmp/outputs/mlpipeline_metrics/data
      - "name": |-
          rf-model-conf_matr
        "path": |-
          /tmp/outputs/conf_matr/data
  - "container":
      "args":
      - |-
        --df-churn-ip
      - |-
        /tmp/inputs/df_churn_ip/data
      - |-
        --parameters
      - |-
        {{inputs.parameters.gridsearch-2-output}}
      - |-
        --conf-matr
      - |-
        /tmp/outputs/conf_matr/data
      - |-
        --mlpipeline-ui-metadata
      - |-
        /tmp/outputs/mlpipeline_ui_metadata/data
      - |-
        --mlpipeline-metrics
      - |-
        /tmp/outputs/mlpipeline_metrics/data
      "command":
      - |-
        sh
      - |-
        -c
      - |-
        (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' 'gcsfs' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'scikit-learn==0.22.2' 'numpy==1.17.2' 'pandas==1.0.3' 'xgboost==1.0.2' 'gcsfs' --user) && "$0" "$@"
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n \
        \   os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\
        \ndef xgb_model(df_churn_ip , \n              parameters , \n            \
        \  conf_matr ,\n              mlpipeline_ui_metadata , mlpipeline_metrics\
        \ ):\n\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection\
        \ import train_test_split\n    import xgboost as xgb\n    from sklearn.metrics\
        \ import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score,\
        \ recall_score, f1_score\n    import json\n    import os\n    import gcsfs\n\
        \    from tensorflow.python.lib.io import file_io\n\n    df_churn = pd.read_csv(df_churn_ip)\n\
        \    df_churn.dropna(inplace=True)\n\n    y1 = df_churn['Churn']\n    X1 =\
        \ df_churn.drop(['Churn'],axis=1)\n\n    X_train, X_test, y_train, y_test\
        \ = train_test_split(X1, y1, random_state=0)\n\n    clfxg = xgb.XGBClassifier(**parameters)\n\
        \    clfxg.fit(X_train, y_train)\n\n    y_test_pred = clfxg.predict(X_test)\n\
        \n    y_test_proba = clfxg.predict_proba(X_test)[:,0]\n\n    xgb_score = float('%.4f'\
        \ %accuracy_score(y_test, y_test_pred))   \n    xgb_precision = float('%.4f'\
        \ %precision_score(y_test, y_test_pred))\n    xgb_recall = float('%.4f' %recall_score(y_test,\
        \ y_test_pred))\n    xgb_f1 = float('%.4f' %f1_score(y_test, y_test_pred))\n\
        \n    print(\"Accuracy, Precision, Recall, f1: \")\n    print(xgb_score, xgb_precision,\
        \ xgb_recall, xgb_f1)\n\n    cm = confusion_matrix(y_test, y_test_pred)\n\
        \    print(\"Confusion Matrix: {}\".format(cm))\n\n    fpr, tpr, thresholds\
        \ = roc_curve(y_test, y_test_proba) \n    auc_score = float('%.4f' %roc_auc_score(y_test,\
        \ y_test_proba))\n    print('Auc score: ')\n    print(auc_score)\n\n    #Converting\
        \ the matrix to a Dataframe\n\n    flags = {0:'Not Churned',1:'Churned'}\n\
        \    flag_list = ['Not Churned','Churned']\n    data = []\n    for target_index,\
        \ target_row in enumerate(cm):\n        for predicted_index, count in enumerate(target_row):\n\
        \            data.append((flags[target_index], flags[predicted_index], count))\n\
        \n    df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])\n\
        \    print(df_cm)\n\n    with file_io.FileIO(conf_matr, 'w') as f:\n     \
        \   df_cm.to_csv(f, columns=['target', 'predicted', 'count'], header=False,\
        \ index=False)\n\n    fs = gcsfs.GCSFileSystem(project='YDataSynthetic', token\
        \ = 'cloud')\n\n    with file_io.FileIO('gs://pipelines_artifacts/Artifacts/XGBConf_mat.csv',\
        \ 'w') as f:\n        df_cm.to_csv(f, columns=['target', 'predicted', 'count'],\
        \ header=False, index=False)\n\n    #roc curve\n\n    df_roc = pd.DataFrame({'fpr':\
        \ fpr, 'tpr': tpr, 'thresholds': thresholds})\n    with file_io.FileIO('gs://pipelines_artifacts/Artifacts/XGBROC_curve.csv',\
        \ 'w') as f:\n        df_roc.to_csv(f, columns=['fpr', 'tpr', 'thresholds'],\
        \ header=False, index=False)\n\n    #code to generate artifacts\n\n    #Artifact\
        \ generator - metadata\n\n    from tensorflow.python.lib.io import file_io\n\
        \    import json\n\n    metadata = {\n        'version' : 1, \n        'outputs'\
        \ : [{\n            'type': 'confusion_matrix',\n            'format': 'csv',\n\
        \            'storage': 'gcs',\n            'schema': [\n                {'name':\
        \ 'target', 'type': 'CATEGORY'},\n                {'name': 'predicted', 'type':\
        \ 'CATEGORY'},\n                {'name': 'count', 'type': 'NUMBER'},\n   \
        \         ],\n            'source': 'gs://pipelines_artifacts/Artifacts/XGBConf_mat.csv',\
        \ #conf_matr\n\n       # Convert flags to string because for bealean values\
        \ we want \"True|False\" to match csv data.\n            'labels': flag_list\n\
        \        },    \n        {\n          'type': 'roc',\n          'format':\
        \ 'csv',\n          'storage': 'gcs',\n          'schema': [\n           \
        \ {'name': 'fpr', 'type': 'NUMBER'},\n            {'name': 'tpr', 'type':\
        \ 'NUMBER'},\n            {'name': 'thresholds', 'type': 'NUMBER'},\n    \
        \      ],\n          'source': 'gs://pipelines_artifacts/Artifacts/XGBROC_curve.csv'\n\
        \        }\n        ]\n    }\n\n    with file_io.FileIO('/mlpipeline-ui-metadata.json',\
        \ 'w') as f:\n        json.dump(metadata, f)\n\n    with file_io.FileIO(mlpipeline_ui_metadata,\
        \ 'w') as f:\n        json.dump(metadata, f)\n\n    metrics = {\n    'metrics':\
        \ [{\n      'name': 'accuracy-score', # The name of the metric. Visualized\
        \ as the column name in the runs table.\n      'numberValue':  xgb_score,\
        \ # The value of the metric. Must be a numeric value.\n      'format': \"\
        RAW\",   # The optional format of the metric. Supported values are \"RAW\"\
        \ (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage format).\n\
        \    },\n    {\n      'name': 'precision-score', # The name of the metric.\
        \ Visualized as the column name in the runs table.\n      'numberValue': \
        \ xgb_precision, # The value of the metric. Must be a numeric value.\n   \
        \   'format': \"RAW\",   # The optional format of the metric. Supported values\
        \ are \"RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage\
        \ format).\n    },\n    {\n      'name': 'recall', # The name of the metric.\
        \ Visualized as the column name in the runs table.\n      'numberValue': \
        \ xgb_recall, # The value of the metric. Must be a numeric value.\n      'format':\
        \ \"RAW\",   # The optional format of the metric. Supported values are \"\
        RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage\
        \ format).\n    },\n    {\n      'name': 'f1-score', # The name of the metric.\
        \ Visualized as the column name in the runs table.\n      'numberValue': \
        \ xgb_f1, # The value of the metric. Must be a numeric value.\n      'format':\
        \ \"RAW\",   # The optional format of the metric. Supported values are \"\
        RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage\
        \ format).\n    },\n    {\n      'name': 'auc-score', # The name of the metric.\
        \ Visualized as the column name in the runs table.\n      'numberValue': \
        \ auc_score, # The value of the metric. Must be a numeric value.\n      'format':\
        \ \"RAW\",   # The optional format of the metric. Supported values are \"\
        RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage\
        \ format).\n    }]\n    }\n\n    with file_io.FileIO('/mlpipeline-metrics.json',\
        \ 'w') as f:\n        json.dump(metrics, f)\n\n    with file_io.FileIO(mlpipeline_metrics,\
        \ 'w') as f:\n        json.dump(metrics, f)\n\nimport json\nimport argparse\n\
        _parser = argparse.ArgumentParser(prog='Xgb model', description='')\n_parser.add_argument(\"\
        --df-churn-ip\", dest=\"df_churn_ip\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--parameters\", dest=\"parameters\", type=json.loads,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--conf-matr\"\
        , dest=\"conf_matr\", type=_make_parent_dirs_and_return_path, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--mlpipeline-ui-metadata\"\
        , dest=\"mlpipeline_ui_metadata\", type=_make_parent_dirs_and_return_path,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--mlpipeline-metrics\"\
        , dest=\"mlpipeline_metrics\", type=_make_parent_dirs_and_return_path, required=True,\
        \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
        _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = xgb_model(**_parsed_args)\n\
        \n_output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
        \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
        \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
      "image": |-
        tensorflow/tensorflow:1.13.2-py3
    "inputs":
      "artifacts":
      - "name": |-
          one-hot-encode-df_one_hot
        "path": |-
          /tmp/inputs/df_churn_ip/data
      "parameters":
      - "name": |-
          gridsearch-2-output
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"inputs": [{"name": "df_churn_ip"}, {"name": "parameters", "type": "JsonObject"}], "name": "Xgb model", "outputs": [{"name": "conf_matr"}, {"name": "mlpipeline_ui_metadata"}, {"name": "mlpipeline_metrics"}]}
    "name": |-
      xgb-model
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /tmp/outputs/mlpipeline_ui_metadata/data
      - "name": |-
          mlpipeline-metrics
        "path": |-
          /tmp/outputs/mlpipeline_metrics/data
      - "name": |-
          xgb-model-conf_matr
        "path": |-
          /tmp/outputs/conf_matr/data
